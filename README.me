# BC Data Pipeline

## ğŸ“– Project Summary

This repository contains an end-to-end data pipeline that ingests Basket Craftâ€™s `website_sessions` data for December 1â€“31, 2023, from a MySQL source into a Postgres raw schema, transforms it through staging and warehouse layers with dbt, and surfaces key session metrics in an interactive Looker Studio dashboard. The pipeline is fully automated via GitHub Actions and follows the modular dbt patterns introduced in Lesson Exercises 10, extended here for Quiz 03.

---

## ğŸ—‚ Repository Structure

```text
.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ basket_craft_extract_load_raw.yml      # CI workflow for ELT automation
â”œâ”€â”€ analyses/                                       # ad-hoc queries & diagrams
â”œâ”€â”€ elt/                                            # extraction & load scripts
â”‚   â”œâ”€â”€ basket_craft_orders_extract_load_raw.py
â”‚   â”œâ”€â”€ basket_craft_products_extract_load_raw.py
â”‚   â””â”€â”€ basket_craft_website_sessions_extract_load_raw.py  # Quiz 03 ELT script
â”œâ”€â”€ logs/                                           # ETL run logs
â”œâ”€â”€ macros/                                         # custom dbt macros
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ generate_schema_name.sql
â”œâ”€â”€ models/                                         # dbt models
â”‚   â”œâ”€â”€ marts/
â”‚   â”‚   â””â”€â”€ finance/
â”‚   â”‚       â””â”€â”€ fct_finance_orders_daily.sql
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ _sources.yml
â”‚   â”‚   â”œâ”€â”€ stg_orders.sql
â”‚   â”‚   â”œâ”€â”€ stg_products.sql
â”‚   â”‚   â”œâ”€â”€ stg_products.yml
â”‚   â”‚   â”œâ”€â”€ stg_website_sessions.sql
â”‚   â”‚   â””â”€â”€ stg_website_sessions.yml
â”‚   â””â”€â”€ warehouse/
â”‚       â”œâ”€â”€ dim_products.sql
â”‚       â”œâ”€â”€ fct_orders_product_daily.sql
â”‚       â””â”€â”€ fct_website_sessions_utm_source_daily.sql
â”œâ”€â”€ seeds/                                          # dbt seed data (if any)
â”œâ”€â”€ snapshots/                                      # dbt snapshots
â”œâ”€â”€ target/                                         # compiled dbt artifacts
â”œâ”€â”€ tests/                                          # custom dbt tests
â”œâ”€â”€ .env                                            # local environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ dbt_project.yml                                 # dbt project config
â”œâ”€â”€ README.md                                       # this file
â””â”€â”€ requirements.txt                                # Python dependencies
```

---

## ğŸ“Š Data Pipeline Diagram

![Pipeline Diagram](analyses/pipeline_diagram.png)
*Illustrates: Extract & Load â†’ Automation â†’ dbt Transform â†’ Looker Studio Visualization*

---

## ğŸš€ Getting Started

### 1. Prerequisites

* Python 3.9+
* Install dependencies:

  ```bash
  pip install -r requirements.txt
  pip install dbt-postgres
  ```
* Access to MySQL & Postgres (credentials via `.env` and `~/.dbt/profiles.yml`)

### 2. Extract & Load

1. Store your DB credentials in `.env` or GitHub Secrets.
2. Run the ELT script locally or let CI run it on a 15-minute cron:

   ```bash
   python elt/basket_craft_website_sessions_extract_load_raw.py
   ```

   This writes December 2023 sessions to `raw.website_sessions` in Postgres.

### 3. Automation

The GitHub Actions workflow (`.github/workflows/basket_craft_extract_load_raw.yml`) triggers the ELT Python script every 15 minutes and supports manual dispatch. Ensure all sensitive credentials are in GitHub Secrets.

### 4. Transform with dbt

1. Configure your Postgres connection in `~/.dbt/profiles.yml`.
2. From the repo root, run:

   ```bash
   dbt clean
   dbt run
   dbt test
   ```
3. Model layers:

   * **Staging**: `models/staging/stg_website_sessions.sql` (rename fields, add `loaded_at`)
   * **Warehouse**: `models/warehouse/fct_website_sessions_utm_source_daily.sql` (daily grain, metrics)
   * **Marts**: reserved for future analytics marts

### 5. Visualize in Looker Studio

1. Connect to the Postgres warehouse.
2. Build a dashboard sourcing from `fct_website_sessions_utm_source_daily`:

   * Table: daily sessions
   * Heatmap: % repeat by UTM source
   * Scorecard: total sessions vs. prior period
   * Time series: trend by day
   * Bar chart: sessions by UTM source
3. Enable cross-filtering on all except the scorecard.
4. Set the report to **Unlisted** and paste the link below.

---

## ğŸ“ Dashboard

**Dashboard:** \[Unlisted Looker Studio Link]

---

## ğŸ“ Submission

1. Commit & push all code, configs, workflow, and diagram.
2. Verify ELT script, dbt models, and dashboard link are present.
3. Submit the repo link on Brightspace by the deadline.

